{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOm7GA+3B8JlJWa5JCExqE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tomaszewski-Piotr/grf/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHFKroiLpfQm"
      },
      "source": [
        "import common as common\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import r2_score, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "import os\n",
        "from common import log_verbose\n",
        "import pathlib\n",
        "from joblib import dump, load\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "\n",
        "use_GPU = True   # use GPU when training\n",
        "xgb_verbosity = 1 # verbosity level\n",
        "do_regression_models = True  #skip regression models (only classification training)\n",
        "\n",
        "# creates xgboost regression model for given x, y input\n",
        "# the model is created using 80% of data and evaluated using remaining 20\n",
        "# evaluation results are returned together with the model\n",
        "def create_regression_model(x_all, y_all):\n",
        "\n",
        "    # split into test and train\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x_all, y_all,\n",
        "                                                        test_size=0.2)  # 80% training and 20% test\n",
        "    #train the model\n",
        "    if use_GPU:\n",
        "        xgb_reg = MultiOutputRegressor(xgb.XGBRegressor(verbosity=xgb_verbosity, tree_method='gpu_hist', gpu_id=0))\n",
        "    else:\n",
        "        xgb_reg = MultiOutputRegressor(xgb.XGBRegressor(verbosity=xgb_verbosity))#, tree_method='gpu_hist', gpu_id=0))\n",
        "    xgb_reg.fit(x_train, y_train)\n",
        "\n",
        "    #test on the test set and calculate the metrics\n",
        "    y_pred = xgb_reg.predict(x_test) # Predictions\n",
        "    MSE = mse(y_test, y_pred)\n",
        "    RMSE = np.sqrt(MSE)\n",
        "    R_squared = r2_score(y_test, y_pred)\n",
        "\n",
        "    log_verbose(\"\\nRMSE: \", np.round(RMSE, 2))\n",
        "    log_verbose(\"R-Squared: \", np.round(R_squared, 2))\n",
        "\n",
        "    #prepare actual vs predicted table\n",
        "    out_array = np.concatenate((y_test, y_pred), axis=1)\n",
        "    out = pd.DataFrame(out_array)\n",
        "    no_outputs = y_test.shape[1]\n",
        "\n",
        "    #provide appropriate titles\n",
        "    titles = [None] * no_outputs * 2\n",
        "    for i in range(0, no_outputs):\n",
        "        titles[i] = 'Actual'+str(i+1)\n",
        "        titles[i+no_outputs] = 'Predicted'+str(i+1)\n",
        "    out.columns = titles\n",
        "\n",
        "    return RMSE, R_squared, out, xgb_reg\n",
        "\n",
        "# creates classification model for the provided data set where\n",
        "# classes are placed in \"class\" column\n",
        "#return the model and evaluation results\n",
        "def create_classification_model(classification_set, target):\n",
        "    #separate features from classes\n",
        "    all_x = classification_set.drop(columns=['class', 'porosity'])\n",
        "    # create a dataframe with only the target column\n",
        "    all_y = classification_set[[target]]\n",
        "\n",
        "    #encode the classes (ordinal encoding)\n",
        "    encoder = LabelEncoder()\n",
        "    encoder.fit(all_y.values.ravel())\n",
        "    # get ordinal encoding\n",
        "    all_ordinal_y = encoder.transform(all_y.values.ravel())\n",
        "\n",
        "    #split the dataset in train test 80/20\n",
        "    x_train, x_test, y_train, y_test = train_test_split(all_x, all_ordinal_y,\n",
        "                                                        test_size=0.2)  # 80% training and 20% test\n",
        "    # train the model\n",
        "    if use_GPU:\n",
        "        xgb_classifier = xgb.XGBClassifier(verbosity=xgb_verbosity, use_label_encoder=False, tree_method='gpu_hist', gpu_id=0)\n",
        "    else:\n",
        "        xgb_classifier = xgb.XGBClassifier(verbosity=xgb_verbosity, use_label_encoder=False)  # , tree_method='gpu_hist', gpu_id=0))\n",
        "    xgb_classifier.fit(x_train, y_train)\n",
        "\n",
        "    # test on the test set\n",
        "    y_pred = xgb_classifier.predict(x_test)  # Predictions\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    log_verbose(accuracy)\n",
        "    # store test predictions and the confusion matrix\n",
        "    y_test_names = encoder.inverse_transform(y_test)\n",
        "    y_pred_names = encoder.inverse_transform(y_pred)\n",
        "    cm = confusion_matrix(y_test_names, y_pred_names, labels=encoder.classes_)\n",
        "    cm_df = pd.DataFrame(cm, index=encoder.classes_, columns=encoder.classes_)\n",
        "    out = pd.DataFrame(columns=['Actual', 'Predicted'])\n",
        "    out['Actual'] = y_test_names\n",
        "    out['Actual_encoded'] = y_test\n",
        "    out['Predicted'] = y_pred_names\n",
        "    out['Predicted_encoded'] = y_pred\n",
        "    return xgb_classifier, encoder, accuracy, cm_df, out\n",
        "\n",
        "def process_classification_model(classification_set, name, writer, target):\n",
        "    classification_set_df = pd.concat(classification_set, axis=0, ignore_index=True)\n",
        "    xgb_class, encoder, accuracy, cm, out = create_classification_model(classification_set_df, target)\n",
        "    dump(xgb_class, open(common.out_file(name+'_classifier' + common.model_suffix), \"wb\"))\n",
        "    dump(encoder, open(common.out_file(name+'_encoder' + common.model_suffix), \"wb\"))\n",
        "    out.to_excel(writer, sheet_name = name + '_classification')\n",
        "    cm.to_excel(writer, sheet_name = name + '_confusion matrix')\n",
        "    return accuracy\n",
        "\n",
        "def create_models():\n",
        "    i=0\n",
        "    porosity_classification_set = [] # to be used for classification training\n",
        "    low_classification_set = []  # to be used for classification training\n",
        "    high_classification_set = []  # to be used for classification training\n",
        "    classes = []\n",
        "    with pd.ExcelWriter(common.out_file('output.xlsx')) as writer:\n",
        "        summary = pd.DataFrame(columns=['Name', 'RMSE', 'R_squared', 'Accuracy'])  # report\n",
        "        for x_file_name in common.find_data_csv():\n",
        "            basename = os.path.basename(x_file_name)[2:-len(common.csv_suffix)]\n",
        "            classes.append(basename)\n",
        "            base_dir = os.path.dirname(x_file_name)\n",
        "            y_file_name = pathlib.Path(base_dir, 'y_' + basename + common.csv_suffix)\n",
        "            log_verbose(' Retrieving data for: ' + basename)\n",
        "            x_all = pd.read_csv(x_file_name, header=None)\n",
        "            y_all = pd.read_csv(y_file_name, header=None)\n",
        "            #create regression model for given class\n",
        "            if do_regression_models:\n",
        "                RMSE, R_squared, out, xgb_reg = create_regression_model(x_all, y_all)\n",
        "                summary.loc[i] = [basename, RMSE, R_squared, None]\n",
        "                out.to_excel(writer, sheet_name=basename)\n",
        "                dump(xgb_reg, open(common.out_file(basename+common.model_suffix), \"wb\"))\n",
        "            i = i+1\n",
        "            # first set porosity as the class and add to the complete test set for porosity classification\n",
        "            x_all['porosity'] = re.split('_', basename)[1]\n",
        "            x_all['class'] = basename\n",
        "            porosity_classification_set.append(x_all) #add to the set used to do classification training\n",
        "            #change class to the basename for porosity dependent model classification\n",
        "            if 'low_porosity' in basename:\n",
        "                low_classification_set.append(x_all)  # add to the set used to do classification training\n",
        "            else:\n",
        "                high_classification_set.append(x_all)  # add to the set used to do classification training\n",
        "\n",
        "        dump(classes, open(common.out_file('classes.joblib'), \"wb\"))\n",
        "        # construct the classification model\n",
        "        porosity_accuracy = process_classification_model(porosity_classification_set, 'porosity_pred', writer, 'porosity')\n",
        "        low_accuracy = process_classification_model(low_classification_set, 'low_porosity', writer, 'class')\n",
        "        high_accuracy = process_classification_model(high_classification_set, 'high_porosity', writer, 'class')\n",
        "        summary.loc[i + 1] = ['Porosity classification', None, None, porosity_accuracy]\n",
        "        summary.loc[i + 2] = ['Low porosity classification', None, None, low_accuracy]\n",
        "        summary.loc[i + 3] = ['High porosity classification', None, None, high_accuracy]\n",
        "        summary.to_excel(writer, sheet_name='Summary')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    create_models()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}